{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fake News Detection  \n",
    "## Why 99% Accuracy is a Dangerous Lie  \n",
    "### >>> The Real Number is ~60%\n",
    "\n",
    "**Mesfin Kebede**  \n",
    "Data Science Career Track – Capstone Three  \n",
    "November 19, 2025  \n",
    "\n",
    "GitHub: https://github.com/mesfin-k/capstone-three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Problem Everyone Ignores\n",
    "\n",
    "Most papers report **98–99.9% accuracy**  \n",
    "\n",
    "But they all make the **same critical mistake**:\n",
    "\n",
    "→ Train & test on the **same single dataset**\n",
    "\n",
    "→ Model learns **dataset-specific shortcuts** (style, vocabulary, length), not actual deception\n",
    "\n",
    "**Real world** = infinite sources, styles, topics\n",
    "\n",
    "**This project asks:**  \n",
    "> **What happens when we force models to face multiple domains at once — just like in production?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Datasets Used\n",
    "\n",
    "| Dataset   | Articles  | Real   | Fake   | Key Traits                              |\n",
    "|-----------|-----------|--------|--------|-----------------------------------------|\n",
    "| ISOT      | 44,898   | 21,417 | 23,481 | 2016-2017 politics, Reuters + unreliable, very formal |\n",
    "| WELFake   | 72,134   | 37,106 | 35,028 | Multi-topic, noisy, mixed sources       |\n",
    "| **Merged**| **117,032** | 58,523 | 58,509 | **Source column removed → true real-world test** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This Is Why Models Hit 99% on Single Datasets\n",
    "\n",
    "They exploit **shortcut features**:\n",
    "\n",
    "- ISOT → Reuters writing style = real  \n",
    "- WELFake → different length, noise, topics = fake\n",
    "\n",
    "Even **RoBERTa-Large** gets:\n",
    "\n",
    "- **99.98%** on ISOT alone  \n",
    "- **99.82%** on WELFake alone\n",
    "\n",
    "→ It's basically learning **\"which dataset is this?\"** not \"is this fake?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"text-align:center; margin: 20px 0;\">\n",
       "        <h1 style=\"color:#c0392b; font-size:80px; margin-bottom:0;\">99% → 60%</h1>\n",
       "        <h3 style=\"color:#2c3e50; font-size:30px; margin-top:5px;\">Performance Drop When Tested on Combined Dataset</h3>\n",
       "    </div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e5bd0 th {\n",
       "  font-size: 20pt;\n",
       "  background-color: #34495e;\n",
       "  color: white;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_e5bd0_row0_col0, #T_e5bd0_row0_col1, #T_e5bd0_row0_col2, #T_e5bd0_row1_col0, #T_e5bd0_row1_col1, #T_e5bd0_row1_col2, #T_e5bd0_row2_col0, #T_e5bd0_row2_col1, #T_e5bd0_row2_col2, #T_e5bd0_row3_col0, #T_e5bd0_row3_col1, #T_e5bd0_row3_col2, #T_e5bd0_row4_col0, #T_e5bd0_row4_col1, #T_e5bd0_row4_col2, #T_e5bd0_row5_col0, #T_e5bd0_row5_col1, #T_e5bd0_row5_col2, #T_e5bd0_row6_col0, #T_e5bd0_row6_col1, #T_e5bd0_row6_col2, #T_e5bd0_row7_col0, #T_e5bd0_row7_col1, #T_e5bd0_row7_col2, #T_e5bd0_row8_col0, #T_e5bd0_row8_col1, #T_e5bd0_row8_col2 {\n",
       "  font-size: 18pt;\n",
       "  text-align: center;\n",
       "  border: 1px solid black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e5bd0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e5bd0_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e5bd0_level0_col1\" class=\"col_heading level0 col1\" >Dataset</th>\n",
       "      <th id=\"T_e5bd0_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e5bd0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e5bd0_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_e5bd0_row0_col1\" class=\"data row0 col1\" >ISOT</td>\n",
       "      <td id=\"T_e5bd0_row0_col2\" class=\"data row0 col2\" >98.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5bd0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e5bd0_row1_col0\" class=\"data row1 col0\" >SVM</td>\n",
       "      <td id=\"T_e5bd0_row1_col1\" class=\"data row1 col1\" >ISOT</td>\n",
       "      <td id=\"T_e5bd0_row1_col2\" class=\"data row1 col2\" >98.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5bd0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e5bd0_row2_col0\" class=\"data row2 col0\" >DistilBERT</td>\n",
       "      <td id=\"T_e5bd0_row2_col1\" class=\"data row2 col1\" >ISOT</td>\n",
       "      <td id=\"T_e5bd0_row2_col2\" class=\"data row2 col2\" >99.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5bd0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e5bd0_row3_col0\" class=\"data row3 col0\" >RoBERTa-Large</td>\n",
       "      <td id=\"T_e5bd0_row3_col1\" class=\"data row3 col1\" >ISOT</td>\n",
       "      <td id=\"T_e5bd0_row3_col2\" class=\"data row3 col2\" >99.98%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5bd0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e5bd0_row4_col0\" class=\"data row4 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_e5bd0_row4_col1\" class=\"data row4 col1\" >WELFake</td>\n",
       "      <td id=\"T_e5bd0_row4_col2\" class=\"data row4 col2\" >93.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5bd0_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e5bd0_row5_col0\" class=\"data row5 col0\" >SVM</td>\n",
       "      <td id=\"T_e5bd0_row5_col1\" class=\"data row5 col1\" >WELFake</td>\n",
       "      <td id=\"T_e5bd0_row5_col2\" class=\"data row5 col2\" >95.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5bd0_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e5bd0_row6_col0\" class=\"data row6 col0\" >DistilBERT</td>\n",
       "      <td id=\"T_e5bd0_row6_col1\" class=\"data row6 col1\" >WELFake</td>\n",
       "      <td id=\"T_e5bd0_row6_col2\" class=\"data row6 col2\" >99.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5bd0_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e5bd0_row7_col0\" class=\"data row7 col0\" >RoBERTa-Large</td>\n",
       "      <td id=\"T_e5bd0_row7_col1\" class=\"data row7 col1\" >WELFake</td>\n",
       "      <td id=\"T_e5bd0_row7_col2\" class=\"data row7 col2\" >99.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5bd0_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e5bd0_row8_col0\" class=\"data row8 col0\" >ALL MODELS</td>\n",
       "      <td id=\"T_e5bd0_row8_col1\" class=\"data row8 col1\" >MERGED</td>\n",
       "      <td id=\"T_e5bd0_row8_col2\" class=\"data row8 col2\" >≈60%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b000012fc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Model results\n",
    "results = pd.DataFrame([\n",
    "    [\"Logistic Regression\", \"ISOT\",     \"98.18%\"],\n",
    "    [\"SVM\",                 \"ISOT\",     \"98.97%\"],\n",
    "    [\"DistilBERT\",          \"ISOT\",     \"99.97%\"],\n",
    "    [\"RoBERTa-Large\",       \"ISOT\",     \"99.98%\"],\n",
    "    [\"Logistic Regression\", \"WELFake\",  \"93.97%\"],\n",
    "    [\"SVM\",                 \"WELFake\",  \"95.19%\"],\n",
    "    [\"DistilBERT\",          \"WELFake\",  \"99.10%\"],\n",
    "    [\"RoBERTa-Large\",       \"WELFake\",  \"99.82%\"],\n",
    "    [\"ALL MODELS\",          \"MERGED\",   \"≈60%\"],\n",
    "], columns=[\"Model\", \"Dataset\", \"Accuracy\"])\n",
    "\n",
    "# Title banner\n",
    "display(HTML(\"\"\"\n",
    "    <div style=\"text-align:center; margin: 20px 0;\">\n",
    "        <h1 style=\"color:#c0392b; font-size:80px; margin-bottom:0;\">99% → 60%</h1>\n",
    "        <h3 style=\"color:#2c3e50; font-size:30px; margin-top:5px;\">Performance Drop When Tested on Combined Dataset</h3>\n",
    "    </div>\n",
    "\"\"\"))\n",
    "\n",
    "# Styled table\n",
    "styled = results.style.set_properties(**{\n",
    "    'font-size': '18pt',\n",
    "    'text-align': 'center',\n",
    "    'border': '1px solid black',\n",
    "}).set_table_styles([{\n",
    "    'selector': 'th',\n",
    "    'props': [('font-size', '20pt'),\n",
    "              ('background-color', '#34495e'),\n",
    "              ('color', 'white'),\n",
    "              ('text-align', 'center')]\n",
    "}])\n",
    "\n",
    "display(styled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Proof #1: Text Length Distributions\n",
    "\n",
    "![](images/text_length_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Proof #2: Word Clouds (Fake vs Real)\n",
    "\n",
    "![](images/fake_wordcloud.png)\n",
    "\n",
    "![](images/real_wordcloud.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Proof #3: Top Bigrams\n",
    "\n",
    "**Fake news** loves:  \n",
    "`donald trump` · `hillary clinton` · `white house` · `fake news` · `breaking`\n",
    "\n",
    "**Real news** loves:  \n",
    "`new york` · `united states` · `prime minister` · `last year` · `according to`\n",
    "\n",
    "→ A simple bag-of-words model gets >90% using just these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Full DSM Process Completed (All Rubric Boxes Checked)\n",
    "\n",
    "1. Data wrangling → merged, cleaned, removed source column  \n",
    "2. EDA → length, word clouds, n-grams, statistical tests  \n",
    "3. Feature engineering → TF-IDF, numerical features, standardization  \n",
    "4. Modeling → 5 models (LogReg, SVM, LSTM, DistilBERT, RoBERTa-Large)  \n",
    "5. Evaluation → separate vs merged → comparison table filled  \n",
    "6. Final model selected & applied to merged data  \n",
    "7. 3+ visualizations created  \n",
    "8. PDF report + model metrics file + clean GitHub repo\n",
    "\n",
    "**All steps documented and submitted**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Real State of Fake News Detection\n",
    "\n",
    "**99% on single dataset = misleading/overfitting**\n",
    "\n",
    "**60% on merged data = honest real-world performance**\n",
    "\n",
    "**Conclusion:**  \n",
    "Fake news detection is **nowhere near solved**  \n",
    "Current models will fail in production  \n",
    "\n",
    "This is the clearest evidence yet that we need multi-domain training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3 Concrete Recommendations for Clients\n",
    "\n",
    "1. **Never deploy a model trained on one dataset**  \n",
    "   → Require validation on ≥2 unseen datasets\n",
    "\n",
    "2. **Use domain-adversarial training or style-transfer augmentation**  \n",
    "   → Forces model to ignore writing style\n",
    "\n",
    "3. **Monitor drift monthly & retrain with new sources**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You!\n",
    "\n",
    "**Fake News Detection: The 99% Myth & the 60% Reality**\n",
    "\n",
    "Mesfin Kebede \n",
    "GitHub: https://github.com/mesfin-k/capstone-three  \n",
    "\n",
    "Questions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
