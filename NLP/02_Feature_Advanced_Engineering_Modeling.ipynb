{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dSxbHGBFBHxV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 21759,
          "status": "ok",
          "timestamp": 1763336339291,
          "user": {
            "displayName": "Mesfin Kebede",
            "userId": "16770939845848294057"
          },
          "user_tz": 480
        },
        "id": "dSxbHGBFBHxV",
        "outputId": "20c861bc-e08f-41c4-df52-5216cd1d60c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "JzXUj8qUesPZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4664,
          "status": "ok",
          "timestamp": 1763334126991,
          "user": {
            "displayName": "Mesfin Kebede",
            "userId": "16770939845848294057"
          },
          "user_tz": 480
        },
        "id": "JzXUj8qUesPZ",
        "outputId": "af50a0bf-bfd3-425f-9f86-a4dd1e2b69c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9f64660f-9048-47c3-a139-5ed99b6734c1",
      "metadata": {
        "id": "9f64660f-9048-47c3-a139-5ed99b6734c1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763336342668,
          "user_tz": 480,
          "elapsed": 1783,
          "user": {
            "displayName": "Mesfin Kebede",
            "userId": "16770939845848294057"
          }
        }
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# CORE PYTHON & DATA HANDLING\n",
        "# ============================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# ============================================\n",
        "# VISUALIZATION\n",
        "# ============================================\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# ============================================\n",
        "# NLP PREPROCESSING (NLTK)\n",
        "# ============================================\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('wordnet')\n",
        "\n",
        "# ============================================\n",
        "# CLASSICAL MACHINE LEARNING\n",
        "# ============================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "# ============================================\n",
        "# STATISTICAL TESTS\n",
        "# ============================================\n",
        "from scipy.stats import ttest_ind, mannwhitneyu, chi2_contingency, shapiro\n",
        "\n",
        "# ============================================\n",
        "# SPARSE MATRIX HANDLING\n",
        "# ============================================\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# ============================================\n",
        "# DEEP LEARNING (TF/KERAS)\n",
        "# ============================================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import (\n",
        "    Embedding, LSTM, GRU, Bidirectional,\n",
        "    Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        ")\n",
        "\n",
        "\n",
        "# Hugging Face\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "import evaluate\n",
        "import torch\n",
        "\n",
        "# ============================================\n",
        "# TRANSFORMERS (HUGGINGFACE)\n",
        "# ============================================\n",
        "from transformers import (\n",
        "    DistilBertTokenizerFast,\n",
        "    TFDistilBertForSequenceClassification\n",
        ")\n",
        "\n",
        "# ============================================\n",
        "# MODEL EXPLAINABILITY\n",
        "# ============================================\n",
        "# import shap\n",
        "# from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "# ============================================\n",
        "# UTILITY\n",
        "# ============================================\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "13e62da7-5ce0-4f17-b72b-4cd682e2305d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 17069,
          "status": "ok",
          "timestamp": 1763336362057,
          "user": {
            "displayName": "Mesfin Kebede",
            "userId": "16770939845848294057"
          },
          "user_tz": 480
        },
        "id": "13e62da7-5ce0-4f17-b72b-4cd682e2305d",
        "outputId": "b0b97069-2485-4075-b058-2333dbdb9b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged shape: (101131, 4)\n",
            "Train size: 80904\n",
            "Test size: 20227\n"
          ]
        }
      ],
      "source": [
        "## 2. Load cleaned datasets\n",
        "\n",
        "isot = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data_clean/clean_isot.csv\")\n",
        "wel  = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data_clean/clean_welfake.csv\")\n",
        "\n",
        "# Merge datasets\n",
        "df = pd.concat([isot, wel], ignore_index=True)\n",
        "\n",
        "# Features and labels\n",
        "X = df[\"text_clean\"].astype(str)\n",
        "y = df[\"label\"].astype(int)\n",
        "\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.20,\n",
        "    random_state=47,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Merged shape:\", df.shape)\n",
        "print(\"Train size:\", len(X_train_text))\n",
        "print(\"Test size:\", len(X_test_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "sjD0Sh73eqgV",
      "metadata": {
        "id": "sjD0Sh73eqgV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763334171303,
          "user_tz": 480,
          "elapsed": 5,
          "user": {
            "displayName": "Mesfin Kebede",
            "userId": "16770939845848294057"
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d6360213-14c1-4c01-b2f2-7051c0dd28d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 90583,
          "status": "ok",
          "timestamp": 1763336452651,
          "user": {
            "displayName": "Mesfin Kebede",
            "userId": "16770939845848294057"
          },
          "user_tz": 480
        },
        "id": "d6360213-14c1-4c01-b2f2-7051c0dd28d4",
        "outputId": "87c673cb-0a8c-47ee-e348-ff1c35a6091a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: np.float64(0.9726844282004424), 1: np.float64(1.0288940889205413)}\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Tokenizer\n",
        "# -------------------------\n",
        "VOCAB_SIZE = 50000\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train_text)\n",
        "\n",
        "# Convert to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_test_seq  = tokenizer.texts_to_sequences(X_test_text)\n",
        "\n",
        "# -------------------------\n",
        "# Padding\n",
        "# -------------------------\n",
        "MAX_LEN = 300  # good length for news data\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
        "X_test_pad  = pad_sequences(X_test_seq,  maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "# -------------------------\n",
        "# Compute Class Weights\n",
        "# -------------------------\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "print(\"Class Weights:\", class_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d93ad560-dbb7-4bed-8b67-bffe6cc0366b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "d93ad560-dbb7-4bed-8b67-bffe6cc0366b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763334315164,
          "user_tz": 480,
          "elapsed": 61357,
          "user": {
            "displayName": "Mesfin Kebede",
            "userId": "16770939845848294057"
          }
        },
        "outputId": "304f7ce9-d25e-441c-9565-ea8769f78fbf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
              "\u2503\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\u2503\n",
              "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
              "\u2502 embedding (\u001b[38;5;33mEmbedding\u001b[0m)           \u2502 ?                      \u2502   \u001b[38;5;34m0\u001b[0m (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   \u2502 ?                      \u2502   \u001b[38;5;34m0\u001b[0m (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dropout (\u001b[38;5;33mDropout\u001b[0m)               \u2502 ?                      \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dense (\u001b[38;5;33mDense\u001b[0m)                   \u2502 ?                      \u2502   \u001b[38;5;34m0\u001b[0m (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             \u2502 ?                      \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dense_1 (\u001b[38;5;33mDense\u001b[0m)                 \u2502 ?                      \u2502   \u001b[38;5;34m0\u001b[0m (unbuilt) \u2502\n",
              "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
              "\u2503<span style=\"font-weight: bold\"> Layer (type)                    </span>\u2503<span style=\"font-weight: bold\"> Output Shape           </span>\u2503<span style=\"font-weight: bold\">       Param # </span>\u2503\n",
              "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
              "\u2502 embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           \u2502 ?                      \u2502   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   \u2502 ?                      \u2502   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               \u2502 ?                      \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   \u2502 ?                      \u2502   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             \u2502 ?                      \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 \u2502 ?                      \u2502   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \u2502\n",
              "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.5666 - loss: 0.6479 - val_accuracy: 0.5981 - val_loss: 0.6088\n",
            "Epoch 2/5\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.5920 - loss: 0.6006 - val_accuracy: 0.5862 - val_loss: 0.6121\n",
            "Epoch 3/5\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.6113 - loss: 0.5719 - val_accuracy: 0.5674 - val_loss: 0.6307\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step\n",
            "\n",
            "=== BiLSTM Results ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.89      0.69     10397\n",
            "           1       0.70      0.28      0.40      9830\n",
            "\n",
            "    accuracy                           0.59     20227\n",
            "   macro avg       0.63      0.58      0.55     20227\n",
            "weighted avg       0.63      0.59      0.55     20227\n",
            "\n",
            "Accuracy: 0.5915360656548179\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Build BiLSTM Model\n",
        "# ============================================================\n",
        "\n",
        "EMBED_DIM = 128\n",
        "LSTM_UNITS = 128\n",
        "\n",
        "model_bilstm = Sequential([\n",
        "    Embedding(input_dim=VOCAB_SIZE, output_dim=EMBED_DIM, input_length=MAX_LEN),\n",
        "\n",
        "    # Bidirectional LSTM\n",
        "    tf.keras.layers.Bidirectional(LSTM(LSTM_UNITS, return_sequences=False)),\n",
        "\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_bilstm.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_bilstm.summary()\n",
        "\n",
        "# ============================================================\n",
        "# Train the Model\n",
        "# ============================================================\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=2,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history_bilstm = model_bilstm.fit(\n",
        "    X_train_pad,\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# Evaluate on Test Set\n",
        "# ============================================================\n",
        "\n",
        "pred_probs = model_bilstm.predict(X_test_pad)\n",
        "y_pred = (pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\"\\n=== BiLSTM Results ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "47d1a5c7-2966-46bc-84d0-66d8777087d7",
      "metadata": {
        "id": "47d1a5c7-2966-46bc-84d0-66d8777087d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763334335624,
          "user_tz": 480,
          "elapsed": 20435,
          "user": {
            "displayName": "Mesfin Kebede",
            "userId": "16770939845848294057"
          }
        },
        "outputId": "ee760887-2254-476d-cd06-af37c06e47fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
              "\u2503\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\u2503\n",
              "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
              "\u2502 embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         \u2502 ?                      \u2502   \u001b[38;5;34m0\u001b[0m (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 \u2502 ?                      \u2502   \u001b[38;5;34m0\u001b[0m (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 global_max_pooling1d            \u2502 ?                      \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
              "\u2502 (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            \u2502                        \u2502               \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 reshape (\u001b[38;5;33mReshape\u001b[0m)               \u2502 ?                      \u2502   \u001b[38;5;34m0\u001b[0m (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   \u2502 ?                      \u2502   \u001b[38;5;34m0\u001b[0m (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dense_2 (\u001b[38;5;33mDense\u001b[0m)                 \u2502 ?                      \u2502   \u001b[38;5;34m0\u001b[0m (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             \u2502 ?                      \u2502             \u001b[38;5;34m0\u001b[0m \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dense_3 (\u001b[38;5;33mDense\u001b[0m)                 \u2502 ?                      \u2502   \u001b[38;5;34m0\u001b[0m (unbuilt) \u2502\n",
              "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
              "\u2503<span style=\"font-weight: bold\"> Layer (type)                    </span>\u2503<span style=\"font-weight: bold\"> Output Shape           </span>\u2503<span style=\"font-weight: bold\">       Param # </span>\u2503\n",
              "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
              "\u2502 embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         \u2502 ?                      \u2502   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 \u2502 ?                      \u2502   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 global_max_pooling1d            \u2502 ?                      \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
              "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            \u2502                        \u2502               \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               \u2502 ?                      \u2502   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   \u2502 ?                      \u2502   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 \u2502 ?                      \u2502   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             \u2502 ?                      \u2502             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502\n",
              "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
              "\u2502 dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 \u2502 ?                      \u2502   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \u2502\n",
              "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m506/506\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5550 - loss: 0.6559 - val_accuracy: 0.5951 - val_loss: 0.5815\n",
            "Epoch 2/3\n",
            "\u001b[1m506/506\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6109 - loss: 0.5605 - val_accuracy: 0.5954 - val_loss: 0.5803\n",
            "Epoch 3/3\n",
            "\u001b[1m506/506\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6180 - loss: 0.5377 - val_accuracy: 0.5953 - val_loss: 0.6084\n",
            "\u001b[1m633/633\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "=== CNN-LSTM Results ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.23      0.37     10397\n",
            "           1       0.55      0.99      0.70      9830\n",
            "\n",
            "    accuracy                           0.60     20227\n",
            "   macro avg       0.75      0.61      0.54     20227\n",
            "weighted avg       0.75      0.60      0.53     20227\n",
            "\n",
            "Accuracy: 0.598160874079201\n"
          ]
        }
      ],
      "source": [
        "# =======================================================\n",
        "#  CNN + LSTM Hybrid Model\n",
        "# =======================================================\n",
        "\n",
        "def build_cnn_lstm(vocab_size, max_len):\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len),\n",
        "\n",
        "        # 1D CNN layer\n",
        "        Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
        "\n",
        "        # Max pooling to reduce sequence size\n",
        "        GlobalMaxPooling1D(),\n",
        "\n",
        "        # LSTM block\n",
        "        tf.keras.layers.Reshape((1, 128)),  # reshaping for LSTM\n",
        "        LSTM(64, return_sequences=False),\n",
        "\n",
        "        # Dense layers\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "cnn_lstm_model = build_cnn_lstm(VOCAB_SIZE, MAX_LEN)\n",
        "cnn_lstm_model.summary()\n",
        "\n",
        "history_cnn_lstm = cnn_lstm_model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs=3,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "y_pred_probs = cnn_lstm_model.predict(X_test_pad)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\"\\n=== CNN-LSTM Results ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "acc_cnn_lstm = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", acc_cnn_lstm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "uJ55EkkPZpSv",
      "metadata": {
        "id": "uJ55EkkPZpSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506,
          "referenced_widgets": [
            "4d67465fc39f4f3b9f9cf400875e6df1",
            "84769c55648a4152bb7411196b7c487f",
            "75a86cc71fa445bb954b928aaf978e15",
            "83b15aab98a042fca2c2bb16b2660ccb",
            "4ce1e01a766144a6847b7c85a452f92d",
            "e8292973b5f241e29bd11d36b1462934",
            "da82764ed10542fcac833a5528b9263f",
            "6a35668f1fcd41769a85944f055d7215",
            "b5bd6769fca844788db657b3a4c46cdd",
            "22fa26fc21854f759d20ea4cbf5ab80d",
            "b831a599136f4a0bbec66c78931eeb38",
            "4490ece226e14c9c90a52d9c67443d5b",
            "d107d5766b464da6b311974e307b6d45",
            "5366c1ea0ad84c759d4a74253b4fa2a9",
            "fc582e3ed351452094489ee5ce9ac525",
            "57bf18afdb2242f3aeae6b5e9df73c60",
            "1e7edb491af84b68bdf42d47bd2f3c07",
            "290434d25b34457a99010760d5cb1ac3",
            "b66a2ebdb2c248e8b3df880d5bacd9a6",
            "e6469a986a8545a7b344a31df16fb3fc",
            "65552731707e4b80bf9ce9f003f3e3e6",
            "d933513a2c3149c78409245978127f89",
            "0078fa8005444e2bb73595354bbab9f3",
            "652074b4f2eb4505b98199b2930741de",
            "dfe8e2c7186d4f5a84416a0b694129dd",
            "b424ea0364f24ee78474d2fc11c32385",
            "4eeff065168745caaca0098ec51f7ee5",
            "504bbe63ec094e96a8ab287c30d2d09f",
            "c132ebc2d1fb4fc38e42202c0c882f0e",
            "3d7d5313b0164eea87a1039f343d7202",
            "5dccb11c276b4889a1c048482f528889",
            "b5d281901d2f45129c1bb61f91ffc387",
            "e7c78d134b284df4973c5926558d1cad",
            "afccbd5457ee483290dd4c1c86013b36",
            "ebb7d09b31194e3e85e127c95ee188fd",
            "13bbbb918353434da4ca262da0e05db1",
            "2ee043b727ea44458a50715fcaafa8c0",
            "99b8df5f388042e4b20616f8a74ded03",
            "6fa703bfdd7344539595edf5c7a060c7",
            "89907c22c6994dbaadadadb02a236d0e",
            "7a354cdac8cc4b91bd6792086e114455",
            "f39f74dc655c4e66a7b236140df89576",
            "a403dc05a6834fba9a96c6c462d8c41c",
            "bb69d85d580a407b8461ebbb8fe34064",
            "f4e19cc7d0e848b2a776fcf3985c9ce6",
            "086de5627cde48a3b6543cd85aff493f",
            "55fadd817d314b6796af5d8e58e3a1f2",
            "0c1324990c794345996dbea79bbd551b",
            "2b479ebaceee4033a4e0b3dc3af18f46",
            "1de8be2efb40400c8f9a1893d6e48605",
            "e2b7ac8b8bd64532aaf5df76ad94b1a2",
            "29fa463b54f84ac6941a9b39a5d81765",
            "adefc228886f473190004288877c9656",
            "c6f30cc6e2b44420ad6bef40f9cf25f7",
            "529d892dfa2443deac81df6647b9bb5a",
            "82710fd999534280bd080407257c7676",
            "f6fd2c5527aa4b5d83a9b12707387512",
            "4a3dcdf55f414283ad04c603d09345a9",
            "eda516b8e2da484ba869781440c8cd30",
            "1d3f1638fbd94b5cb78dcce4899ec5c3",
            "b3b0b0c42b674d258f891f221c6b74b5",
            "12de991df4b9422bad2e25e04346667f",
            "ef7cd87d13854cbf8574e5acb50f61a0",
            "77f5608bfcce497ea4a3fc22e56569ea",
            "1f0e2337f9ed424e98ce77aadf6d8386",
            "b7c8f0ee56a0452c879b00ff1b878fea",
            "7399049f490d4989826746a35a1d1cbe",
            "a9b9c52596d245ebb5344e29bf4da827",
            "da9a74cc133447fbbf3480045b11f845",
            "3d40990ae7394ef993f1f9f80e57f34d",
            "8c3cf9f5669e456799fef5fbff78cf68",
            "950ff3bb94f642a5b9f627b1b2d75fea",
            "94eee9285a9642d7ad39d7495cb90aa3",
            "74b76a4c12e24208bef8e4c711e539c7",
            "fe84027d0f4e434ab275a8aa8f655ab6",
            "24eb3dd9897f4463a3ec2044551d5351",
            "791990eef58b4dc48d5c6877b0efaad9",
            "76df81ab84ac47ba96d070dc9554a99c",
            "69389d9d505f43dab184a165d6ec6de0",
            "3df3d9c88f5041189bbda5d91fa7fcd6",
            "1c8d72ce3cee49fba0fe10ce8d07adee",
            "fbcd9838b8b947aab76af31bbbd09a28",
            "584a2116d6e54d63b5598c7aeaa847ed",
            "c8d28ffcaaff47378e6cc1b5e6d53fbb",
            "419370fd4116443f9ec2481b67a1b7e1",
            "8586230f8dd34aa6828e9773bbfdc4d5",
            "54eb178985d14cbfa466b96f303acbea",
            "1d107c887ebb41899ae9b50b5374a4ae"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763335781288,
          "user_tz": 480,
          "elapsed": 1445641,
          "user": {
            "displayName": "Mesfin Kebede",
            "userId": "16770939845848294057"
          }
        },
        "outputId": "5c843b55-6ff8-41e9-a00c-d4e2e9736ead"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d67465fc39f4f3b9f9cf400875e6df1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4490ece226e14c9c90a52d9c67443d5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0078fa8005444e2bb73595354bbab9f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afccbd5457ee483290dd4c1c86013b36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/80904 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4e19cc7d0e848b2a776fcf3985c9ce6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20227 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82710fd999534280bd080407257c7676"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7399049f490d4989826746a35a1d1cbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76df81ab84ac47ba96d070dc9554a99c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10114' max='10114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10114/10114 22:07, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.557900</td>\n",
              "      <td>0.565966</td>\n",
              "      <td>0.608148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.540900</td>\n",
              "      <td>0.553510</td>\n",
              "      <td>0.608543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1265' max='1265' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1265/1265 00:45]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DistilBERT Final Results ===\n",
            "{'eval_loss': 0.5535104870796204, 'eval_accuracy': 0.608543036535324, 'eval_runtime': 45.7364, 'eval_samples_per_second': 442.251, 'eval_steps_per_second': 27.658, 'epoch': 2.0}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import evaluate\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"  # No WandB prompt\n",
        "\n",
        "# Prepare data for HF\n",
        "df[['text_clean', 'label']].rename(columns={'text_clean': 'text'}).to_csv('merged_hf.csv', index=False)\n",
        "data = pd.read_csv('merged_hf.csv')\n",
        "\n",
        "# Stratified split (rubric-approved: handles imbalance)\n",
        "train_df, test_df = train_test_split(\n",
        "    data, test_size=0.2, random_state=47, stratify=data['label']\n",
        ")\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df)\n",
        "test_ds  = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, max_length=512)\n",
        "\n",
        "tokenized_train = train_ds.map(tokenize_function, batched=True)\n",
        "tokenized_test  = test_ds.map(tokenize_function, batched=True)\n",
        "\n",
        "# Dynamic padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Accuracy metric\n",
        "accuracy = evaluate.load('accuracy')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased', num_labels=2\n",
        ")\n",
        "\n",
        "# Training arguments (correct parameter names for 2025 versions)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./distilbert-fake-news',\n",
        "    num_train_epochs=2,                  # 2 is enough for capstone\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy='epoch',         # Corrected from evaluation_strategy\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    report_to=\"none\",                    # Extra safety - no WandB\n",
        "    fp16=True,                           # Use GPU mixed precision (faster on Colab)\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train!\n",
        "trainer.train()\n",
        "\n",
        "# Final evaluation\n",
        "results = trainer.evaluate()\n",
        "print(\"=== DistilBERT Final Results ===\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets evaluate accelerate --quiet\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import evaluate\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"   # Disable W&B\n",
        "\n",
        "# === Load your cleaned CSV ===\n",
        "df[['text_clean', 'label']].rename(columns={'text_clean': 'text'}).to_csv(\"merged_hf.csv\", index=False)\n",
        "data = pd.read_csv(\"merged_hf.csv\")\n",
        "\n",
        "# === Stratified train/test split ===\n",
        "train_df, test_df = train_test_split(\n",
        "    data,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=data['label']\n",
        ")\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df)\n",
        "test_ds  = Dataset.from_pandas(test_df)\n",
        "\n",
        "# === Tokenizer (RoBERTa-LARGE) ===\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
        "\n",
        "tokenized_train = train_ds.map(tokenize_function, batched=True)\n",
        "tokenized_test  = test_ds.map(tokenize_function, batched=True)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# === Metrics ===\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return accuracy.compute(predictions=preds, references=labels)\n",
        "\n",
        "# === Model (RoBERTa-LARGE) ===\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"roberta-large\",\n",
        "    num_labels=2\n",
        ")\n",
        "\n",
        "# === Training arguments ===\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./roberta-large-fake-news\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=4,         # IMPORTANT for large model VRAM\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,         # Effective batch size = 16\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# === Trainer ===\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# === Train ===\n",
        "trainer.train()\n",
        "\n",
        "# === Final Evaluation ===\n",
        "results = trainer.evaluate()\n",
        "print(\"=== RoBERTa-LARGE Final Results ===\")\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403,
          "referenced_widgets": [
            "13f19d7da4ff460a91d29b5800903754",
            "0413a8e54474440b9326760804d1ead4",
            "90f933b5879848a2abf0f9acf7f12efb",
            "a2e59ef90bde427ea2c3bf6d3b6c12b1",
            "383210d8ed674d0dac7bc7bbc6c9427e",
            "e2fb02b381ad4ed9959349836299348c",
            "4af528fdf626414da7b7303c108ea480",
            "1347bb2b8d8b4388b653290de374f082",
            "52db0c9498db4e93951b63f1b55f5bd0",
            "e6b2c9faa2c34d168debb09bf1b3aa41",
            "63a0e1d2f0b44972bed0c993d9205f66",
            "f4f0842cc36d4ddea1df8c82218a16f6",
            "2d892dd9c2a74f778fc0defcef4c53f3",
            "3284c2912572455f9f9ade7cd4459e46",
            "66597f6c6d9141beb49fcec3f564166a",
            "9fa15353a4b64566baf11206c64a2802",
            "9939c51a62c84128b4c64568384d9dd9",
            "96ed4eba606b41b6b570bf3966635056",
            "4725a967ec8c4ed18f0858ca99f57d31",
            "c0bd2cf6d52a4bcbb355a010685e6630",
            "398372ac7b0d43b5af1b84a259d35c68",
            "1fe3241da1204338a58f87a9c3807d2d"
          ]
        },
        "id": "PqcfiO3r57Vy",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763343719905,
          "user_tz": 480,
          "elapsed": 718822,
          "user": {
            "displayName": "Mesfin Kebede",
            "userId": "16770939845848294057"
          }
        },
        "outputId": "444c4081-a937-4025-f235-de46d34d0b2d"
      },
      "id": "PqcfiO3r57Vy",
      "execution_count": 7,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13f19d7da4ff460a91d29b5800903754",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/80904 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4f0842cc36d4ddea1df8c82218a16f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20227 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8932' max='10114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 8932/10114 54:23 < 07:11, 2.74 it/s, Epoch 1.77/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.557200</td>\n",
              "      <td>0.545571</td>\n",
              "      <td>0.615761</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10114' max='10114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10114/10114 1:03:50, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.557200</td>\n",
              "      <td>0.545571</td>\n",
              "      <td>0.615761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.541100</td>\n",
              "      <td>0.540575</td>\n",
              "      <td>0.616602</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5057' max='5057' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5057/5057 02:32]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== RoBERTa-LARGE Final Results ===\n",
            "{'eval_loss': 0.5405745506286621, 'eval_accuracy': 0.6166015721560291, 'eval_runtime': 152.2225, 'eval_samples_per_second': 132.878, 'eval_steps_per_second': 33.221, 'epoch': 2.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!find \"/content/drive\" -name \"*.ipynb\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym5Lvmkog3qP",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1763344825808,
          "user_tz": 480,
          "elapsed": 1019,
          "user": {
            "displayName": "Mesfin Kebede",
            "userId": "16770939845848294057"
          }
        },
        "outputId": "d6dbae71-8a33-4671-d8c9-7cbfbc479cbe"
      },
      "id": "Ym5Lvmkog3qP",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/Untitled0.ipynb\n",
            "/content/drive/MyDrive/Colab Notebooks/Untitled1.ipynb\n",
            "/content/drive/MyDrive/Colab Notebooks/Untitled2.ipynb\n",
            "/content/drive/MyDrive/Colab Notebooks/02_feature_engineering_modeling_part2.ipynb\n",
            "/content/drive/MyDrive/Colab Notebooks/Untitled3.ipynb\n",
            "/content/drive/MyDrive/Colab Notebooks/Untitled4.ipynb\n",
            "/content/drive/MyDrive/Colab Notebooks/Untitled5.ipynb\n",
            "/content/drive/MyDrive/Colab Notebooks/02_Feature_Advanced_Engineering_Modeling.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lqC8rGy9hNAv"
      },
      "id": "lqC8rGy9hNAv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
